{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wandb in /home/mnk2978/.local/lib/python3.8/site-packages (0.12.16)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb) (2.24.0)\n",
      "Requirement already satisfied: pathtools in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (1.5.12)\n",
      "Requirement already satisfied: setuptools in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from wandb) (49.2.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (3.20.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/mnk2978/.local/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.25.10)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/mnk2978/.local/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/mnk2978/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in /home/mnk2978/.local/lib/python3.8/site-packages (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmnk2978\u001b[0m (\u001b[33mmrunal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/mnk2978/hpml/finalproj/ModelParallel/wandb/run-20220512_005629-26k2qmeu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mrunal/TinyImagenetModelParallel/runs/26k2qmeu\" target=\"_blank\">Resnet50ModelParallel</a></strong> to <a href=\"https://wandb.ai/mrunal/TinyImagenetModelParallel\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/mrunal/TinyImagenetModelParallel/runs/26k2qmeu?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x14ae1cc0b8b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Some helper functions for PyTorch, including:\n",
    "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
    "    - msr_init: net parameter initialization.\n",
    "    - progress_bar: progress bar mimic xlua.progress.\n",
    "'''\n",
    "!pip3 install wandb\n",
    "!pip3 install torchsummary\n",
    "\n",
    "#import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import shutil \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import wandb\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "wandb.init(project=\"TinyImagenetModelParallel\", name=\"Resnet50ModelParallel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "_, term_width = shutil.get_terminal_size()\n",
    "#_, term_width = os.popen('stty size', 'r').read().split()\n",
    "term_width = int(term_width)\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "==> Building model..\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=2048, out_features=200, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pkgpath = './'\n",
    "save_path = './results/'\n",
    "\n",
    "if os.path.isdir(save_path) == False:\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "sys.path.append(pkgpath)\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(64, padding=8),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dir = './tiny-imagenet-200/train'\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(\n",
    "    train_dir, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=100, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dir = './tiny-imagenet-200/val/images'\n",
    "testset = torchvision.datasets.ImageFolder(\n",
    "    test_dir, transform=transform_test) \n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=0)\n",
    "classes = 200\n",
    "img_size = 64\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "\n",
    "num_classes = 200\n",
    "\n",
    "print(ResNet)\n",
    "class ModelParallelResNet50(ResNet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModelParallelResNet50, self).__init__(\n",
    "            Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)\n",
    "\n",
    "        self.seq1 = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "\n",
    "            self.layer1,\n",
    "            self.layer2\n",
    "        ).to('cuda:0')\n",
    "\n",
    "        self.seq2 = nn.Sequential(\n",
    "            self.layer3,\n",
    "            self.layer4,\n",
    "            self.avgpool,\n",
    "        ).to('cuda:1')\n",
    "\n",
    "        self.fc.to('cuda:1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq2(self.seq1(x).to('cuda:1'))\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "    \n",
    "net = models.resnet50()\n",
    "\n",
    "\n",
    "#Finetune Final few layers to adjust for tiny imagenet input\n",
    "net.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "net.fc.out_features = 200\n",
    "print\n",
    "\n",
    "net = net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "print(net)\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0/90\n",
      " [================================================================>]  Step: 1s396ms | Tot: 2m22s | train_Loss: 5.366 | train_Acc: 1.520% (1520/100000) 1000/1000 \n",
      ">>>best acc: 0, mean: 7.0, std: 0.0................................]  Step: 211ms | Tot: 0ms | test_Loss: 4.341 | test_Acc: 7.000% (7/100) 1/100 \n",
      ">>>best acc: 0, mean: 6.75, std: 0.25..............................]  Step: 109ms | Tot: 110ms | test_Loss: 4.518 | test_Acc: 6.500% (13/200) 2/100 \n",
      ">>>best acc: 0, mean: 5.94, std: 1.16..............................]  Step: 108ms | Tot: 218ms | test_Loss: 4.532 | test_Acc: 4.333% (13/300) 3/100 \n",
      ">>>best acc: 0, mean: 5.83, std: 1.02..............................]  Step: 110ms | Tot: 329ms | test_Loss: 4.507 | test_Acc: 5.500% (22/400) 4/100 \n",
      ">>>best acc: 0, mean: 5.55, std: 1.08..............................]  Step: 107ms | Tot: 436ms | test_Loss: 4.537 | test_Acc: 4.400% (22/500) 5/100 \n",
      ">>>best acc: 0, mean: 5.23, std: 1.21..............................]  Step: 120ms | Tot: 557ms | test_Loss: 4.547 | test_Acc: 3.667% (22/600) 6/100 \n",
      ">>>best acc: 0, mean: 5.14, std: 1.14..............................]  Step: 112ms | Tot: 669ms | test_Loss: 4.480 | test_Acc: 4.571% (32/700) 7/100 \n",
      ">>>best acc: 0, mean: 5.0, std: 1.13...............................]  Step: 109ms | Tot: 778ms | test_Loss: 4.540 | test_Acc: 4.000% (32/800) 8/100 \n",
      ">>>best acc: 0, mean: 4.84, std: 1.16..............................]  Step: 109ms | Tot: 887ms | test_Loss: 4.650 | test_Acc: 3.556% (32/900) 9/100 \n",
      ">>>best acc: 0, mean: 4.67, std: 1.21..............................]  Step: 114ms | Tot: 1s1ms | test_Loss: 4.663 | test_Acc: 3.200% (32/1000) 10/100 \n",
      ">>>best acc: 0, mean: 4.52, std: 1.25..............................]  Step: 107ms | Tot: 1s109ms | test_Loss: 4.682 | test_Acc: 3.000% (33/1100) 11/100 \n",
      ">>>best acc: 0, mean: 4.43, std: 1.23..............................]  Step: 106ms | Tot: 1s215ms | test_Loss: 4.651 | test_Acc: 3.417% (41/1200) 12/100 \n",
      ">>>best acc: 0, mean: 4.33, std: 1.23..............................]  Step: 106ms | Tot: 1s322ms | test_Loss: 4.709 | test_Acc: 3.154% (41/1300) 13/100 \n",
      ">>>best acc: 0, mean: 4.23, std: 1.24..............................]  Step: 105ms | Tot: 1s427ms | test_Loss: 4.750 | test_Acc: 2.929% (41/1400) 14/100 \n",
      ">>>best acc: 0, mean: 4.13, std: 1.25..............................]  Step: 130ms | Tot: 1s558ms | test_Loss: 4.787 | test_Acc: 2.733% (41/1500) 15/100 \n",
      ">>>best acc: 0, mean: 4.04, std: 1.26..............................]  Step: 105ms | Tot: 1s664ms | test_Loss: 4.785 | test_Acc: 2.750% (44/1600) 16/100 \n",
      ">>>best acc: 0, mean: 3.96, std: 1.27..............................]  Step: 108ms | Tot: 1s773ms | test_Loss: 4.817 | test_Acc: 2.588% (44/1700) 17/100 \n",
      ">>>best acc: 0, mean: 3.87, std: 1.28..............................]  Step: 109ms | Tot: 1s883ms | test_Loss: 4.818 | test_Acc: 2.444% (44/1800) 18/100 \n",
      ">>>best acc: 0, mean: 3.84, std: 1.25..............................]  Step: 109ms | Tot: 1s992ms | test_Loss: 4.796 | test_Acc: 3.263% (62/1900) 19/100 \n",
      ">>>best acc: 0, mean: 3.81, std: 1.23..............................]  Step: 105ms | Tot: 2s97ms | test_Loss: 4.795 | test_Acc: 3.100% (62/2000) 20/100 \n",
      ">>>best acc: 0, mean: 3.76, std: 1.22..............................]  Step: 108ms | Tot: 2s205ms | test_Loss: 4.799 | test_Acc: 2.952% (62/2100) 21/100 \n",
      ">>>best acc: 0, mean: 3.72, std: 1.21..............................]  Step: 106ms | Tot: 2s312ms | test_Loss: 4.797 | test_Acc: 2.818% (62/2200) 22/100 \n",
      ">>>best acc: 0, mean: 3.68, std: 1.2...............................]  Step: 107ms | Tot: 2s420ms | test_Loss: 4.784 | test_Acc: 2.696% (62/2300) 23/100 \n",
      ">>>best acc: 0, mean: 3.63, std: 1.19..............................]  Step: 119ms | Tot: 2s539ms | test_Loss: 4.803 | test_Acc: 2.583% (62/2400) 24/100 \n",
      ">>>best acc: 0, mean: 3.59, std: 1.19..............................]  Step: 107ms | Tot: 2s646ms | test_Loss: 4.813 | test_Acc: 2.480% (62/2500) 25/100 \n",
      ">>>best acc: 0, mean: 3.54, std: 1.19..............................]  Step: 106ms | Tot: 2s753ms | test_Loss: 4.804 | test_Acc: 2.500% (65/2600) 26/100 \n",
      ">>>best acc: 0, mean: 3.53, std: 1.17..............................]  Step: 108ms | Tot: 2s861ms | test_Loss: 4.779 | test_Acc: 3.185% (86/2700) 27/100 \n",
      ">>>best acc: 0, mean: 3.56, std: 1.15..............................]  Step: 107ms | Tot: 2s969ms | test_Loss: 4.752 | test_Acc: 4.286% (120/2800) 28/100 \n",
      ">>>best acc: 0, mean: 3.58, std: 1.14..............................]  Step: 106ms | Tot: 3s75ms | test_Loss: 4.751 | test_Acc: 4.138% (120/2900) 29/100 \n",
      ">>>best acc: 0, mean: 3.59, std: 1.12..............................]  Step: 109ms | Tot: 3s184ms | test_Loss: 4.762 | test_Acc: 4.000% (120/3000) 30/100 \n",
      ">>>best acc: 0, mean: 3.6, std: 1.1................................]  Step: 108ms | Tot: 3s293ms | test_Loss: 4.772 | test_Acc: 3.871% (120/3100) 31/100 \n",
      ">>>best acc: 0, mean: 3.61, std: 1.09..............................]  Step: 108ms | Tot: 3s401ms | test_Loss: 4.785 | test_Acc: 3.750% (120/3200) 32/100 \n",
      ">>>best acc: 0, mean: 3.61, std: 1.07..............................]  Step: 128ms | Tot: 3s530ms | test_Loss: 4.786 | test_Acc: 3.636% (120/3300) 33/100 \n",
      ">>>best acc: 0, mean: 3.6, std: 1.05...............................]  Step: 108ms | Tot: 3s638ms | test_Loss: 4.794 | test_Acc: 3.529% (120/3400) 34/100 \n",
      ">>>best acc: 0, mean: 3.6, std: 1.04...............................]  Step: 108ms | Tot: 3s747ms | test_Loss: 4.799 | test_Acc: 3.429% (120/3500) 35/100 \n",
      ">>>best acc: 0, mean: 3.59, std: 1.03..............................]  Step: 108ms | Tot: 3s856ms | test_Loss: 4.792 | test_Acc: 3.361% (121/3600) 36/100 \n",
      ">>>best acc: 0, mean: 3.58, std: 1.01..............................]  Step: 107ms | Tot: 3s964ms | test_Loss: 4.808 | test_Acc: 3.270% (121/3700) 37/100 \n",
      ">>>best acc: 0, mean: 3.57, std: 1.0...............................]  Step: 114ms | Tot: 4s78ms | test_Loss: 4.811 | test_Acc: 3.237% (123/3800) 38/100 \n",
      ">>>best acc: 0, mean: 3.56, std: 0.99..............................]  Step: 105ms | Tot: 4s184ms | test_Loss: 4.816 | test_Acc: 3.179% (124/3900) 39/100 \n",
      ">>>best acc: 0, mean: 3.55, std: 0.98..............................]  Step: 108ms | Tot: 4s292ms | test_Loss: 4.825 | test_Acc: 3.100% (124/4000) 40/100 \n",
      ">>>best acc: 0, mean: 3.54, std: 0.97..............................]  Step: 106ms | Tot: 4s399ms | test_Loss: 4.821 | test_Acc: 3.073% (126/4100) 41/100 \n",
      ">>>best acc: 0, mean: 3.54, std: 0.96..............................]  Step: 113ms | Tot: 4s512ms | test_Loss: 4.821 | test_Acc: 3.500% (147/4200) 42/100 \n",
      ">>>best acc: 0, mean: 3.54, std: 0.95..............................]  Step: 111ms | Tot: 4s623ms | test_Loss: 4.832 | test_Acc: 3.419% (147/4300) 43/100 \n",
      ">>>best acc: 0, mean: 3.53, std: 0.94..............................]  Step: 106ms | Tot: 4s730ms | test_Loss: 4.845 | test_Acc: 3.341% (147/4400) 44/100 \n",
      ">>>best acc: 0, mean: 3.53, std: 0.93..............................]  Step: 108ms | Tot: 4s838ms | test_Loss: 4.849 | test_Acc: 3.267% (147/4500) 45/100 \n",
      ">>>best acc: 0, mean: 3.52, std: 0.92..............................]  Step: 106ms | Tot: 4s944ms | test_Loss: 4.854 | test_Acc: 3.196% (147/4600) 46/100 \n",
      ">>>best acc: 0, mean: 3.51, std: 0.91..............................]  Step: 110ms | Tot: 5s55ms | test_Loss: 4.853 | test_Acc: 3.170% (149/4700) 47/100 \n",
      ">>>best acc: 0, mean: 3.51, std: 0.9...............................]  Step: 106ms | Tot: 5s161ms | test_Loss: 4.849 | test_Acc: 3.375% (162/4800) 48/100 \n",
      ">>>best acc: 0, mean: 3.51, std: 0.89..............................]  Step: 107ms | Tot: 5s269ms | test_Loss: 4.843 | test_Acc: 3.347% (164/4900) 49/100 \n",
      ">>>best acc: 0, mean: 3.5, std: 0.88...............................]  Step: 106ms | Tot: 5s376ms | test_Loss: 4.850 | test_Acc: 3.280% (164/5000) 50/100 \n",
      ">>>best acc: 0, mean: 3.5, std: 0.88...............................]  Step: 106ms | Tot: 5s482ms | test_Loss: 4.839 | test_Acc: 3.255% (166/5100) 51/100 \n",
      ">>>best acc: 0, mean: 3.49, std: 0.87..............................]  Step: 132ms | Tot: 5s615ms | test_Loss: 4.844 | test_Acc: 3.192% (166/5200) 52/100 \n",
      ">>>best acc: 0, mean: 3.48, std: 0.86..............................]  Step: 109ms | Tot: 5s724ms | test_Loss: 4.848 | test_Acc: 3.132% (166/5300) 53/100 \n",
      ">>>best acc: 0, mean: 3.48, std: 0.86..............................]  Step: 108ms | Tot: 5s832ms | test_Loss: 4.854 | test_Acc: 3.074% (166/5400) 54/100 \n",
      ">>>best acc: 0, mean: 3.47, std: 0.85>.............................]  Step: 106ms | Tot: 5s939ms | test_Loss: 4.856 | test_Acc: 3.018% (166/5500) 55/100 \n",
      ">>>best acc: 0, mean: 3.46, std: 0.84>.............................]  Step: 112ms | Tot: 6s52ms | test_Loss: 4.850 | test_Acc: 3.071% (172/5600) 56/100 \n",
      ">>>best acc: 0, mean: 3.45, std: 0.84=>............................]  Step: 108ms | Tot: 6s160ms | test_Loss: 4.854 | test_Acc: 3.035% (173/5700) 57/100 \n",
      ">>>best acc: 0, mean: 3.45, std: 0.83==>...........................]  Step: 107ms | Tot: 6s268ms | test_Loss: 4.854 | test_Acc: 3.000% (174/5800) 58/100 \n",
      ">>>best acc: 0, mean: 3.44, std: 0.83==>...........................]  Step: 107ms | Tot: 6s375ms | test_Loss: 4.859 | test_Acc: 2.949% (174/5900) 59/100 \n",
      ">>>best acc: 0, mean: 3.43, std: 0.83===>..........................]  Step: 105ms | Tot: 6s481ms | test_Loss: 4.856 | test_Acc: 2.900% (174/6000) 60/100 \n",
      ">>>best acc: 0, mean: 3.42, std: 0.82====>.........................]  Step: 119ms | Tot: 6s600ms | test_Loss: 4.853 | test_Acc: 2.869% (175/6100) 61/100 \n",
      ">>>best acc: 0, mean: 3.41, std: 0.82====>.........................]  Step: 106ms | Tot: 6s707ms | test_Loss: 4.858 | test_Acc: 2.823% (175/6200) 62/100 \n",
      ">>>best acc: 0, mean: 3.4, std: 0.82======>........................]  Step: 108ms | Tot: 6s815ms | test_Loss: 4.866 | test_Acc: 2.778% (175/6300) 63/100 \n",
      ">>>best acc: 0, mean: 3.39, std: 0.81=====>........................]  Step: 107ms | Tot: 6s923ms | test_Loss: 4.876 | test_Acc: 2.734% (175/6400) 64/100 \n",
      ">>>best acc: 0, mean: 3.38, std: 0.81======>.......................]  Step: 114ms | Tot: 7s37ms | test_Loss: 4.882 | test_Acc: 2.692% (175/6500) 65/100 \n",
      ">>>best acc: 0, mean: 3.37, std: 0.81=======>......................]  Step: 109ms | Tot: 7s146ms | test_Loss: 4.894 | test_Acc: 2.652% (175/6600) 66/100 \n",
      ">>>best acc: 0, mean: 3.36, std: 0.81=======>......................]  Step: 112ms | Tot: 7s259ms | test_Loss: 4.892 | test_Acc: 2.612% (175/6700) 67/100 \n",
      ">>>best acc: 0, mean: 3.34, std: 0.81========>.....................]  Step: 110ms | Tot: 7s369ms | test_Loss: 4.902 | test_Acc: 2.574% (175/6800) 68/100 \n",
      ">>>best acc: 0, mean: 3.33, std: 0.81=========>....................]  Step: 111ms | Tot: 7s481ms | test_Loss: 4.902 | test_Acc: 2.536% (175/6900) 69/100 \n",
      ">>>best acc: 0, mean: 3.32, std: 0.81=========>....................]  Step: 132ms | Tot: 7s614ms | test_Loss: 4.911 | test_Acc: 2.500% (175/7000) 70/100 \n",
      ">>>best acc: 0, mean: 3.31, std: 0.81==========>...................]  Step: 109ms | Tot: 7s723ms | test_Loss: 4.919 | test_Acc: 2.465% (175/7100) 71/100 \n",
      ">>>best acc: 0, mean: 3.3, std: 0.81============>..................]  Step: 112ms | Tot: 7s836ms | test_Loss: 4.920 | test_Acc: 2.431% (175/7200) 72/100 \n",
      ">>>best acc: 0, mean: 3.29, std: 0.81===========>..................]  Step: 108ms | Tot: 7s945ms | test_Loss: 4.914 | test_Acc: 2.726% (199/7300) 73/100 \n",
      ">>>best acc: 0, mean: 3.28, std: 0.81============>.................]  Step: 112ms | Tot: 8s57ms | test_Loss: 4.916 | test_Acc: 2.689% (199/7400) 74/100 \n",
      ">>>best acc: 0, mean: 3.27, std: 0.8==============>................]  Step: 111ms | Tot: 8s169ms | test_Loss: 4.921 | test_Acc: 2.653% (199/7500) 75/100 \n",
      ">>>best acc: 0, mean: 3.26, std: 0.8==============>................]  Step: 112ms | Tot: 8s281ms | test_Loss: 4.924 | test_Acc: 2.618% (199/7600) 76/100 \n",
      ">>>best acc: 0, mean: 3.26, std: 0.8===============>...............]  Step: 117ms | Tot: 8s399ms | test_Loss: 4.921 | test_Acc: 2.610% (201/7700) 77/100 \n",
      ">>>best acc: 0, mean: 3.25, std: 0.8================>..............]  Step: 110ms | Tot: 8s510ms | test_Loss: 4.918 | test_Acc: 2.590% (202/7800) 78/100 \n",
      ">>>best acc: 0, mean: 3.24, std: 0.8================>..............]  Step: 122ms | Tot: 8s632ms | test_Loss: 4.920 | test_Acc: 2.557% (202/7900) 79/100 \n",
      ">>>best acc: 0, mean: 3.23, std: 0.8=================>.............]  Step: 110ms | Tot: 8s743ms | test_Loss: 4.923 | test_Acc: 2.538% (203/8000) 80/100 \n",
      ">>>best acc: 0, mean: 3.22, std: 0.79=================>............]  Step: 106ms | Tot: 8s849ms | test_Loss: 4.927 | test_Acc: 2.506% (203/8100) 81/100 \n",
      ">>>best acc: 0, mean: 3.21, std: 0.79=================>............]  Step: 108ms | Tot: 8s958ms | test_Loss: 4.917 | test_Acc: 2.598% (213/8200) 82/100 \n",
      ">>>best acc: 0, mean: 3.21, std: 0.79==================>...........]  Step: 113ms | Tot: 9s71ms | test_Loss: 4.915 | test_Acc: 2.639% (219/8300) 83/100 \n",
      ">>>best acc: 0, mean: 3.2, std: 0.79===================>...........]  Step: 111ms | Tot: 9s183ms | test_Loss: 4.915 | test_Acc: 2.655% (223/8400) 84/100 \n",
      ">>>best acc: 0, mean: 3.19, std: 0.79===================>..........]  Step: 107ms | Tot: 9s291ms | test_Loss: 4.919 | test_Acc: 2.624% (223/8500) 85/100 \n",
      ">>>best acc: 0, mean: 3.19, std: 0.78====================>.........]  Step: 112ms | Tot: 9s403ms | test_Loss: 4.914 | test_Acc: 2.756% (237/8600) 86/100 \n",
      ">>>best acc: 0, mean: 3.18, std: 0.78====================>.........]  Step: 111ms | Tot: 9s514ms | test_Loss: 4.918 | test_Acc: 2.724% (237/8700) 87/100 \n",
      ">>>best acc: 0, mean: 3.18, std: 0.78=====================>........]  Step: 156ms | Tot: 9s670ms | test_Loss: 4.926 | test_Acc: 2.693% (237/8800) 88/100 \n",
      ">>>best acc: 0, mean: 3.17, std: 0.77======================>.......]  Step: 109ms | Tot: 9s780ms | test_Loss: 4.928 | test_Acc: 2.663% (237/8900) 89/100 \n",
      ">>>best acc: 0, mean: 3.17, std: 0.77======================>.......]  Step: 109ms | Tot: 9s889ms | test_Loss: 4.924 | test_Acc: 2.811% (253/9000) 90/100 \n",
      ">>>best acc: 0, mean: 3.16, std: 0.77=======================>......]  Step: 109ms | Tot: 9s999ms | test_Loss: 4.931 | test_Acc: 2.780% (253/9100) 91/100 \n",
      ">>>best acc: 0, mean: 3.16, std: 0.76========================>.....]  Step: 115ms | Tot: 10s115ms | test_Loss: 4.928 | test_Acc: 2.750% (253/9200) 92/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.76========================>.....]  Step: 110ms | Tot: 10s225ms | test_Loss: 4.932 | test_Acc: 2.720% (253/9300) 93/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.76=========================>....]  Step: 110ms | Tot: 10s335ms | test_Loss: 4.922 | test_Acc: 2.787% (262/9400) 94/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.76==========================>...]  Step: 109ms | Tot: 10s445ms | test_Loss: 4.914 | test_Acc: 2.884% (274/9500) 95/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.75==========================>...]  Step: 121ms | Tot: 10s566ms | test_Loss: 4.908 | test_Acc: 3.031% (291/9600) 96/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.75===========================>..]  Step: 111ms | Tot: 10s678ms | test_Loss: 4.903 | test_Acc: 3.103% (301/9700) 97/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.74============================>.]  Step: 107ms | Tot: 10s785ms | test_Loss: 4.890 | test_Acc: 3.367% (330/9800) 98/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.74============================>.]  Step: 108ms | Tot: 10s893ms | test_Loss: 4.883 | test_Acc: 3.333% (330/9900) 99/100 \n",
      " [================================================================>]  Step: 108ms | Tot: 11s2ms | test_Loss: 4.876 | test_Acc: 3.300% (330/10000) 100/100 \n",
      ">>>best acc: 0, mean: 3.15, std: 0.74\n",
      "Saving..\n",
      ">>>best acc: 3.3\n",
      "Epoch:1/90\n",
      " [================================================================>]  Step: 293ms | Tot: 2m17s | train_Loss: 4.579 | train_Acc: 6.478% (6478/100000) 1000/1000  \n",
      ">>>best acc: 3.3, mean: 23.0, std: 0.0.............................]  Step: 90ms | Tot: 0ms | test_Loss: 3.626 | test_Acc: 23.000% (23/100) 1/100 \n",
      ">>>best acc: 3.3, mean: 17.5, std: 5.5.............................]  Step: 77ms | Tot: 78ms | test_Loss: 4.189 | test_Acc: 12.000% (24/200) 2/100 \n",
      ">>>best acc: 3.3, mean: 14.44, std: 6.23...........................]  Step: 78ms | Tot: 156ms | test_Loss: 4.297 | test_Acc: 8.333% (25/300) 3/100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>best acc: 3.3, mean: 12.77, std: 6.13...........................]  Step: 83ms | Tot: 240ms | test_Loss: 4.213 | test_Acc: 7.750% (31/400) 4/100 \n",
      ">>>best acc: 3.3, mean: 12.02, std: 5.68...........................]  Step: 78ms | Tot: 319ms | test_Loss: 4.142 | test_Acc: 9.000% (45/500) 5/100 \n",
      ">>>best acc: 3.3, mean: 11.79, std: 5.21...........................]  Step: 98ms | Tot: 417ms | test_Loss: 4.066 | test_Acc: 10.667% (64/600) 6/100 \n",
      ">>>best acc: 3.3, mean: 12.23, std: 4.94...........................]  Step: 80ms | Tot: 498ms | test_Loss: 3.897 | test_Acc: 14.857% (104/700) 7/100 \n",
      ">>>best acc: 3.3, mean: 12.48, std: 4.67...........................]  Step: 77ms | Tot: 575ms | test_Loss: 3.947 | test_Acc: 14.250% (114/800) 8/100 \n",
      ">>>best acc: 3.3, mean: 12.5, std: 4.41............................]  Step: 78ms | Tot: 654ms | test_Loss: 4.037 | test_Acc: 12.667% (114/900) 9/100 \n",
      ">>>best acc: 3.3, mean: 12.39, std: 4.19...........................]  Step: 84ms | Tot: 739ms | test_Loss: 4.095 | test_Acc: 11.400% (114/1000) 10/100 \n",
      ">>>best acc: 3.3, mean: 12.27, std: 4.02...........................]  Step: 79ms | Tot: 818ms | test_Loss: 4.130 | test_Acc: 11.000% (121/1100) 11/100 \n",
      ">>>best acc: 3.3, mean: 12.22, std: 3.85...........................]  Step: 80ms | Tot: 899ms | test_Loss: 4.045 | test_Acc: 11.667% (140/1200) 12/100 \n",
      ">>>best acc: 3.3, mean: 12.11, std: 3.72...........................]  Step: 78ms | Tot: 978ms | test_Loss: 4.106 | test_Acc: 10.846% (141/1300) 13/100 \n",
      ">>>best acc: 3.3, mean: 11.98, std: 3.61...........................]  Step: 78ms | Tot: 1s57ms | test_Loss: 4.156 | test_Acc: 10.286% (144/1400) 14/100 \n",
      ">>>best acc: 3.3, mean: 11.83, std: 3.53...........................]  Step: 81ms | Tot: 1s138ms | test_Loss: 4.167 | test_Acc: 9.800% (147/1500) 15/100 \n",
      ">>>best acc: 3.3, mean: 11.67, std: 3.48...........................]  Step: 89ms | Tot: 1s228ms | test_Loss: 4.210 | test_Acc: 9.250% (148/1600) 16/100 \n",
      ">>>best acc: 3.3, mean: 11.5, std: 3.44............................]  Step: 79ms | Tot: 1s307ms | test_Loss: 4.243 | test_Acc: 8.706% (148/1700) 17/100 \n",
      ">>>best acc: 3.3, mean: 11.33, std: 3.42...........................]  Step: 81ms | Tot: 1s389ms | test_Loss: 4.265 | test_Acc: 8.389% (151/1800) 18/100 \n",
      ">>>best acc: 3.3, mean: 11.23, std: 3.35...........................]  Step: 81ms | Tot: 1s470ms | test_Loss: 4.205 | test_Acc: 9.579% (182/1900) 19/100 \n",
      ">>>best acc: 3.3, mean: 11.13, std: 3.3............................]  Step: 80ms | Tot: 1s550ms | test_Loss: 4.208 | test_Acc: 9.100% (182/2000) 20/100 \n",
      ">>>best acc: 3.3, mean: 11.04, std: 3.25...........................]  Step: 81ms | Tot: 1s631ms | test_Loss: 4.201 | test_Acc: 9.190% (193/2100) 21/100 \n",
      ">>>best acc: 3.3, mean: 10.95, std: 3.2............................]  Step: 82ms | Tot: 1s713ms | test_Loss: 4.191 | test_Acc: 9.091% (200/2200) 22/100 \n",
      ">>>best acc: 3.3, mean: 10.89, std: 3.14...........................]  Step: 79ms | Tot: 1s793ms | test_Loss: 4.149 | test_Acc: 9.652% (222/2300) 23/100 \n",
      ">>>best acc: 3.3, mean: 10.83, std: 3.09...........................]  Step: 80ms | Tot: 1s874ms | test_Loss: 4.160 | test_Acc: 9.375% (225/2400) 24/100 \n",
      ">>>best acc: 3.3, mean: 10.79, std: 3.03...........................]  Step: 83ms | Tot: 1s957ms | test_Loss: 4.156 | test_Acc: 9.880% (247/2500) 25/100 \n",
      ">>>best acc: 3.3, mean: 10.74, std: 2.98...........................]  Step: 82ms | Tot: 2s39ms | test_Loss: 4.181 | test_Acc: 9.500% (247/2600) 26/100 \n",
      ">>>best acc: 3.3, mean: 10.7, std: 2.94............................]  Step: 82ms | Tot: 2s122ms | test_Loss: 4.170 | test_Acc: 9.593% (259/2700) 27/100 \n",
      ">>>best acc: 3.3, mean: 10.65, std: 2.89...........................]  Step: 83ms | Tot: 2s206ms | test_Loss: 4.181 | test_Acc: 9.429% (264/2800) 28/100 \n",
      ">>>best acc: 3.3, mean: 10.6, std: 2.85............................]  Step: 87ms | Tot: 2s293ms | test_Loss: 4.186 | test_Acc: 9.207% (267/2900) 29/100 \n",
      ">>>best acc: 3.3, mean: 10.56, std: 2.82...........................]  Step: 97ms | Tot: 2s391ms | test_Loss: 4.194 | test_Acc: 9.233% (277/3000) 30/100 \n",
      ">>>best acc: 3.3, mean: 10.5, std: 2.79............................]  Step: 84ms | Tot: 2s476ms | test_Loss: 4.207 | test_Acc: 8.935% (277/3100) 31/100 \n",
      ">>>best acc: 3.3, mean: 10.46, std: 2.75...........................]  Step: 82ms | Tot: 2s558ms | test_Loss: 4.201 | test_Acc: 9.125% (292/3200) 32/100 \n",
      ">>>best acc: 3.3, mean: 10.41, std: 2.72...........................]  Step: 79ms | Tot: 2s638ms | test_Loss: 4.220 | test_Acc: 8.909% (294/3300) 33/100 \n",
      ">>>best acc: 3.3, mean: 10.36, std: 2.7............................]  Step: 81ms | Tot: 2s719ms | test_Loss: 4.237 | test_Acc: 8.647% (294/3400) 34/100 \n",
      ">>>best acc: 3.3, mean: 10.32, std: 2.68...........................]  Step: 86ms | Tot: 2s806ms | test_Loss: 4.236 | test_Acc: 8.714% (305/3500) 35/100 \n",
      ">>>best acc: 3.3, mean: 10.28, std: 2.65...........................]  Step: 82ms | Tot: 2s888ms | test_Loss: 4.208 | test_Acc: 9.111% (328/3600) 36/100 \n",
      ">>>best acc: 3.3, mean: 10.25, std: 2.62...........................]  Step: 82ms | Tot: 2s970ms | test_Loss: 4.209 | test_Acc: 9.027% (334/3700) 37/100 \n",
      ">>>best acc: 3.3, mean: 10.22, std: 2.59...........................]  Step: 81ms | Tot: 3s52ms | test_Loss: 4.216 | test_Acc: 9.158% (348/3800) 38/100 \n",
      ">>>best acc: 3.3, mean: 10.19, std: 2.56...........................]  Step: 81ms | Tot: 3s133ms | test_Loss: 4.245 | test_Acc: 8.923% (348/3900) 39/100 \n",
      ">>>best acc: 3.3, mean: 10.16, std: 2.54...........................]  Step: 90ms | Tot: 3s224ms | test_Loss: 4.246 | test_Acc: 9.075% (363/4000) 40/100 \n",
      ">>>best acc: 3.3, mean: 10.13, std: 2.51...........................]  Step: 85ms | Tot: 3s310ms | test_Loss: 4.256 | test_Acc: 8.951% (367/4100) 41/100 \n",
      ">>>best acc: 3.3, mean: 10.11, std: 2.49...........................]  Step: 82ms | Tot: 3s392ms | test_Loss: 4.248 | test_Acc: 9.262% (389/4200) 42/100 \n",
      ">>>best acc: 3.3, mean: 10.09, std: 2.46...........................]  Step: 80ms | Tot: 3s473ms | test_Loss: 4.250 | test_Acc: 9.209% (396/4300) 43/100 \n",
      ">>>best acc: 3.3, mean: 10.07, std: 2.44...........................]  Step: 80ms | Tot: 3s553ms | test_Loss: 4.248 | test_Acc: 9.250% (407/4400) 44/100 \n",
      ">>>best acc: 3.3, mean: 10.05, std: 2.41...........................]  Step: 83ms | Tot: 3s637ms | test_Loss: 4.251 | test_Acc: 9.156% (412/4500) 45/100 \n",
      ">>>best acc: 3.3, mean: 10.03, std: 2.39...........................]  Step: 81ms | Tot: 3s719ms | test_Loss: 4.241 | test_Acc: 9.457% (435/4600) 46/100 \n",
      ">>>best acc: 3.3, mean: 10.02, std: 2.36...........................]  Step: 85ms | Tot: 3s804ms | test_Loss: 4.245 | test_Acc: 9.340% (439/4700) 47/100 \n",
      ">>>best acc: 3.3, mean: 10.0, std: 2.34............................]  Step: 79ms | Tot: 3s884ms | test_Loss: 4.237 | test_Acc: 9.208% (442/4800) 48/100 \n",
      ">>>best acc: 3.3, mean: 9.99, std: 2.32............................]  Step: 78ms | Tot: 3s963ms | test_Loss: 4.229 | test_Acc: 9.245% (453/4900) 49/100 \n",
      ">>>best acc: 3.3, mean: 9.97, std: 2.3.............................]  Step: 80ms | Tot: 4s43ms | test_Loss: 4.238 | test_Acc: 9.080% (454/5000) 50/100 \n",
      ">>>best acc: 3.3, mean: 9.95, std: 2.28............................]  Step: 82ms | Tot: 4s126ms | test_Loss: 4.230 | test_Acc: 9.137% (466/5100) 51/100 \n",
      ">>>best acc: 3.3, mean: 9.94, std: 2.26............................]  Step: 80ms | Tot: 4s207ms | test_Loss: 4.233 | test_Acc: 9.173% (477/5200) 52/100 \n",
      ">>>best acc: 3.3, mean: 9.92, std: 2.24............................]  Step: 85ms | Tot: 4s293ms | test_Loss: 4.235 | test_Acc: 9.113% (483/5300) 53/100 \n",
      ">>>best acc: 3.3, mean: 9.91, std: 2.22............................]  Step: 81ms | Tot: 4s374ms | test_Loss: 4.233 | test_Acc: 9.204% (497/5400) 54/100 \n",
      ">>>best acc: 3.3, mean: 9.89, std: 2.21............................]  Step: 100ms | Tot: 4s475ms | test_Loss: 4.240 | test_Acc: 9.055% (498/5500) 55/100 \n",
      ">>>best acc: 3.3, mean: 9.88, std: 2.19............................]  Step: 84ms | Tot: 4s559ms | test_Loss: 4.239 | test_Acc: 9.268% (519/5600) 56/100 \n",
      ">>>best acc: 3.3, mean: 9.87, std: 2.17............................]  Step: 80ms | Tot: 4s640ms | test_Loss: 4.249 | test_Acc: 9.140% (521/5700) 57/100 \n",
      ">>>best acc: 3.3, mean: 9.86, std: 2.15>...........................]  Step: 80ms | Tot: 4s720ms | test_Loss: 4.225 | test_Acc: 9.569% (555/5800) 58/100 \n",
      ">>>best acc: 3.3, mean: 9.86, std: 2.14>...........................]  Step: 86ms | Tot: 4s807ms | test_Loss: 4.231 | test_Acc: 9.542% (563/5900) 59/100 \n",
      ">>>best acc: 3.3, mean: 9.86, std: 2.12=>..........................]  Step: 83ms | Tot: 4s890ms | test_Loss: 4.222 | test_Acc: 9.767% (586/6000) 60/100 \n",
      ">>>best acc: 3.3, mean: 9.85, std: 2.1===>.........................]  Step: 81ms | Tot: 4s972ms | test_Loss: 4.227 | test_Acc: 9.607% (586/6100) 61/100 \n",
      ">>>best acc: 3.3, mean: 9.85, std: 2.08==>.........................]  Step: 78ms | Tot: 5s51ms | test_Loss: 4.239 | test_Acc: 9.452% (586/6200) 62/100 \n",
      ">>>best acc: 3.3, mean: 9.84, std: 2.07===>........................]  Step: 78ms | Tot: 5s130ms | test_Loss: 4.234 | test_Acc: 9.460% (596/6300) 63/100 \n",
      ">>>best acc: 3.3, mean: 9.83, std: 2.05===>........................]  Step: 80ms | Tot: 5s210ms | test_Loss: 4.236 | test_Acc: 9.469% (606/6400) 64/100 \n",
      ">>>best acc: 3.3, mean: 9.83, std: 2.04====>.......................]  Step: 94ms | Tot: 5s304ms | test_Loss: 4.239 | test_Acc: 9.508% (618/6500) 65/100 \n",
      ">>>best acc: 3.3, mean: 9.82, std: 2.02=====>......................]  Step: 77ms | Tot: 5s381ms | test_Loss: 4.247 | test_Acc: 9.409% (621/6600) 66/100 \n",
      ">>>best acc: 3.3, mean: 9.82, std: 2.01=====>......................]  Step: 78ms | Tot: 5s460ms | test_Loss: 4.238 | test_Acc: 9.701% (650/6700) 67/100 \n",
      ">>>best acc: 3.3, mean: 9.82, std: 1.99======>.....................]  Step: 78ms | Tot: 5s539ms | test_Loss: 4.253 | test_Acc: 9.662% (657/6800) 68/100 \n",
      ">>>best acc: 3.3, mean: 9.82, std: 1.98=======>....................]  Step: 79ms | Tot: 5s618ms | test_Loss: 4.260 | test_Acc: 9.522% (657/6900) 69/100 \n",
      ">>>best acc: 3.3, mean: 9.81, std: 1.96=======>....................]  Step: 79ms | Tot: 5s697ms | test_Loss: 4.273 | test_Acc: 9.386% (657/7000) 70/100 \n",
      ">>>best acc: 3.3, mean: 9.8, std: 1.95=========>...................]  Step: 163ms | Tot: 5s861ms | test_Loss: 4.281 | test_Acc: 9.282% (659/7100) 71/100 \n",
      ">>>best acc: 3.3, mean: 9.8, std: 1.94==========>..................]  Step: 83ms | Tot: 5s944ms | test_Loss: 4.279 | test_Acc: 9.375% (675/7200) 72/100 \n",
      ">>>best acc: 3.3, mean: 9.79, std: 1.93=========>..................]  Step: 77ms | Tot: 6s22ms | test_Loss: 4.269 | test_Acc: 9.726% (710/7300) 73/100 \n",
      ">>>best acc: 3.3, mean: 9.79, std: 1.91==========>.................]  Step: 80ms | Tot: 6s103ms | test_Loss: 4.267 | test_Acc: 9.662% (715/7400) 74/100 \n",
      ">>>best acc: 3.3, mean: 9.79, std: 1.9============>................]  Step: 78ms | Tot: 6s181ms | test_Loss: 4.268 | test_Acc: 9.600% (720/7500) 75/100 \n",
      ">>>best acc: 3.3, mean: 9.79, std: 1.89===========>................]  Step: 80ms | Tot: 6s261ms | test_Loss: 4.274 | test_Acc: 9.500% (722/7600) 76/100 \n",
      ">>>best acc: 3.3, mean: 9.78, std: 1.88============>...............]  Step: 79ms | Tot: 6s340ms | test_Loss: 4.271 | test_Acc: 9.545% (735/7700) 77/100 \n",
      ">>>best acc: 3.3, mean: 9.78, std: 1.86=============>..............]  Step: 83ms | Tot: 6s424ms | test_Loss: 4.280 | test_Acc: 9.423% (735/7800) 78/100 \n",
      ">>>best acc: 3.3, mean: 9.77, std: 1.85=============>..............]  Step: 99ms | Tot: 6s524ms | test_Loss: 4.281 | test_Acc: 9.304% (735/7900) 79/100 \n",
      ">>>best acc: 3.3, mean: 9.77, std: 1.84==============>.............]  Step: 77ms | Tot: 6s601ms | test_Loss: 4.289 | test_Acc: 9.200% (736/8000) 80/100 \n",
      ">>>best acc: 3.3, mean: 9.76, std: 1.83===============>............]  Step: 77ms | Tot: 6s679ms | test_Loss: 4.299 | test_Acc: 9.099% (737/8100) 81/100 \n",
      ">>>best acc: 3.3, mean: 9.75, std: 1.82===============>............]  Step: 79ms | Tot: 6s758ms | test_Loss: 4.292 | test_Acc: 9.159% (751/8200) 82/100 \n",
      ">>>best acc: 3.3, mean: 9.74, std: 1.81================>...........]  Step: 79ms | Tot: 6s837ms | test_Loss: 4.290 | test_Acc: 9.265% (769/8300) 83/100 \n",
      ">>>best acc: 3.3, mean: 9.74, std: 1.8=================>...........]  Step: 84ms | Tot: 6s922ms | test_Loss: 4.280 | test_Acc: 9.357% (786/8400) 84/100 \n",
      ">>>best acc: 3.3, mean: 9.73, std: 1.79=================>..........]  Step: 76ms | Tot: 6s999ms | test_Loss: 4.292 | test_Acc: 9.259% (787/8500) 85/100 \n",
      ">>>best acc: 3.3, mean: 9.73, std: 1.78==================>.........]  Step: 78ms | Tot: 7s77ms | test_Loss: 4.298 | test_Acc: 9.198% (791/8600) 86/100 \n",
      ">>>best acc: 3.3, mean: 9.72, std: 1.77==================>.........]  Step: 77ms | Tot: 7s155ms | test_Loss: 4.299 | test_Acc: 9.207% (801/8700) 87/100 \n",
      ">>>best acc: 3.3, mean: 9.72, std: 1.76===================>........]  Step: 79ms | Tot: 7s234ms | test_Loss: 4.300 | test_Acc: 9.216% (811/8800) 88/100 \n",
      ">>>best acc: 3.3, mean: 9.71, std: 1.75====================>.......]  Step: 90ms | Tot: 7s324ms | test_Loss: 4.293 | test_Acc: 9.371% (834/8900) 89/100 \n",
      ">>>best acc: 3.3, mean: 9.71, std: 1.74====================>.......]  Step: 83ms | Tot: 7s408ms | test_Loss: 4.289 | test_Acc: 9.478% (853/9000) 90/100 \n",
      ">>>best acc: 3.3, mean: 9.71, std: 1.73=====================>......]  Step: 78ms | Tot: 7s486ms | test_Loss: 4.295 | test_Acc: 9.374% (853/9100) 91/100 \n",
      ">>>best acc: 3.3, mean: 9.7, std: 1.73=======================>.....]  Step: 77ms | Tot: 7s563ms | test_Loss: 4.295 | test_Acc: 9.272% (853/9200) 92/100 \n",
      ">>>best acc: 3.3, mean: 9.7, std: 1.72=======================>.....]  Step: 77ms | Tot: 7s641ms | test_Loss: 4.296 | test_Acc: 9.247% (860/9300) 93/100 \n",
      ">>>best acc: 3.3, mean: 9.69, std: 1.71=======================>....]  Step: 78ms | Tot: 7s719ms | test_Loss: 4.282 | test_Acc: 9.479% (891/9400) 94/100 \n",
      ">>>best acc: 3.3, mean: 9.69, std: 1.7=========================>...]  Step: 78ms | Tot: 7s798ms | test_Loss: 4.272 | test_Acc: 9.684% (920/9500) 95/100 \n",
      ">>>best acc: 3.3, mean: 9.7, std: 1.69=========================>...]  Step: 78ms | Tot: 7s877ms | test_Loss: 4.261 | test_Acc: 9.844% (945/9600) 96/100 \n",
      ">>>best acc: 3.3, mean: 9.7, std: 1.68==========================>..]  Step: 84ms | Tot: 7s961ms | test_Loss: 4.251 | test_Acc: 9.969% (967/9700) 97/100 \n",
      ">>>best acc: 3.3, mean: 9.7, std: 1.67===========================>.]  Step: 77ms | Tot: 8s39ms | test_Loss: 4.247 | test_Acc: 9.898% (970/9800) 98/100 \n",
      ">>>best acc: 3.3, mean: 9.7, std: 1.67===========================>.]  Step: 78ms | Tot: 8s118ms | test_Loss: 4.251 | test_Acc: 9.808% (971/9900) 99/100 \n",
      " [================================================================>]  Step: 81ms | Tot: 8s199ms | test_Loss: 4.245 | test_Acc: 10.010% (1001/10000) 100/100 \n",
      ">>>best acc: 3.3, mean: 9.7, std: 1.66\n",
      "Saving..\n",
      ">>>best acc: 10.01\n",
      "Epoch:2/90\n",
      " [================================================================>]  Step: 289ms | Tot: 2m12s | train_Loss: 4.028 | train_Acc: 13.079% (13079/100000) 1000/1000 \n",
      ">>>best acc: 10.01, mean: 33.0, std: 0.0...........................]  Step: 81ms | Tot: 0ms | test_Loss: 3.224 | test_Acc: 33.000% (33/100) 1/100 \n",
      ">>>best acc: 10.01, mean: 25.25, std: 7.75.........................]  Step: 73ms | Tot: 73ms | test_Loss: 4.228 | test_Acc: 17.500% (35/200) 2/100 \n",
      ">>>best acc: 10.01, mean: 21.39, std: 8.36.........................]  Step: 78ms | Tot: 152ms | test_Loss: 4.347 | test_Acc: 13.667% (41/300) 3/100 \n",
      ">>>best acc: 10.01, mean: 19.1, std: 8.25..........................]  Step: 74ms | Tot: 227ms | test_Loss: 4.262 | test_Acc: 12.250% (49/400) 4/100 \n",
      ">>>best acc: 10.01, mean: 18.24, std: 7.58.........................]  Step: 75ms | Tot: 302ms | test_Loss: 4.097 | test_Acc: 14.800% (74/500) 5/100 \n",
      ">>>best acc: 10.01, mean: 17.54, std: 7.1..........................]  Step: 74ms | Tot: 377ms | test_Loss: 4.108 | test_Acc: 14.000% (84/600) 6/100 \n",
      ">>>best acc: 10.01, mean: 17.5, std: 6.57..........................]  Step: 73ms | Tot: 450ms | test_Loss: 3.946 | test_Acc: 17.286% (121/700) 7/100 \n",
      ">>>best acc: 10.01, mean: 17.64, std: 6.16.........................]  Step: 74ms | Tot: 525ms | test_Loss: 3.931 | test_Acc: 18.625% (149/800) 8/100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>best acc: 10.01, mean: 17.58, std: 5.81.........................]  Step: 81ms | Tot: 607ms | test_Loss: 3.995 | test_Acc: 17.111% (154/900) 9/100 \n",
      ">>>best acc: 10.01, mean: 17.48, std: 5.52.........................]  Step: 74ms | Tot: 681ms | test_Loss: 4.001 | test_Acc: 16.600% (166/1000) 10/100 \n",
      ">>>best acc: 10.01, mean: 17.36, std: 5.27.........................]  Step: 73ms | Tot: 754ms | test_Loss: 4.032 | test_Acc: 16.091% (177/1100) 11/100 \n",
      ">>>best acc: 10.01, mean: 17.42, std: 5.05.........................]  Step: 73ms | Tot: 828ms | test_Loss: 3.899 | test_Acc: 18.083% (217/1200) 12/100 \n",
      ">>>best acc: 10.01, mean: 17.39, std: 4.86.........................]  Step: 74ms | Tot: 903ms | test_Loss: 3.971 | test_Acc: 17.000% (221/1300) 13/100 \n",
      ">>>best acc: 10.01, mean: 17.3, std: 4.69..........................]  Step: 77ms | Tot: 980ms | test_Loss: 4.017 | test_Acc: 16.214% (227/1400) 14/100 \n",
      ">>>best acc: 10.01, mean: 17.19, std: 4.55.........................]  Step: 76ms | Tot: 1s57ms | test_Loss: 4.069 | test_Acc: 15.667% (235/1500) 15/100 \n",
      ">>>best acc: 10.01, mean: 17.06, std: 4.43.........................]  Step: 81ms | Tot: 1s139ms | test_Loss: 4.111 | test_Acc: 15.125% (242/1600) 16/100 \n",
      ">>>best acc: 10.01, mean: 16.92, std: 4.34.........................]  Step: 75ms | Tot: 1s215ms | test_Loss: 4.155 | test_Acc: 14.647% (249/1700) 17/100 \n",
      ">>>best acc: 10.01, mean: 16.77, std: 4.26.........................]  Step: 74ms | Tot: 1s289ms | test_Loss: 4.158 | test_Acc: 14.222% (256/1800) 18/100 \n",
      ">>>best acc: 10.01, mean: 16.67, std: 4.17.........................]  Step: 74ms | Tot: 1s364ms | test_Loss: 4.123 | test_Acc: 14.789% (281/1900) 19/100 \n",
      ">>>best acc: 10.01, mean: 16.56, std: 4.09.........................]  Step: 82ms | Tot: 1s447ms | test_Loss: 4.119 | test_Acc: 14.450% (289/2000) 20/100 \n",
      ">>>best acc: 10.01, mean: 16.43, std: 4.03.........................]  Step: 82ms | Tot: 1s529ms | test_Loss: 4.129 | test_Acc: 14.000% (294/2100) 21/100 \n",
      ">>>best acc: 10.01, mean: 16.31, std: 3.98.........................]  Step: 76ms | Tot: 1s605ms | test_Loss: 4.143 | test_Acc: 13.636% (300/2200) 22/100 \n",
      ">>>best acc: 10.01, mean: 16.24, std: 3.91.........................]  Step: 83ms | Tot: 1s689ms | test_Loss: 4.087 | test_Acc: 14.826% (341/2300) 23/100 \n",
      ">>>best acc: 10.01, mean: 16.17, std: 3.84.........................]  Step: 79ms | Tot: 1s768ms | test_Loss: 4.095 | test_Acc: 14.583% (350/2400) 24/100 \n",
      ">>>best acc: 10.01, mean: 16.09, std: 3.78.........................]  Step: 86ms | Tot: 1s855ms | test_Loss: 4.139 | test_Acc: 14.040% (351/2500) 25/100 \n",
      ">>>best acc: 10.01, mean: 16.01, std: 3.73.........................]  Step: 79ms | Tot: 1s934ms | test_Loss: 4.136 | test_Acc: 13.923% (362/2600) 26/100 \n",
      ">>>best acc: 10.01, mean: 15.92, std: 3.69.........................]  Step: 78ms | Tot: 2s12ms | test_Loss: 4.137 | test_Acc: 13.778% (372/2700) 27/100 \n",
      ">>>best acc: 10.01, mean: 15.85, std: 3.64.........................]  Step: 74ms | Tot: 2s86ms | test_Loss: 4.144 | test_Acc: 13.929% (390/2800) 28/100 \n",
      ">>>best acc: 10.01, mean: 15.79, std: 3.59.........................]  Step: 81ms | Tot: 2s168ms | test_Loss: 4.139 | test_Acc: 14.207% (412/2900) 29/100 \n",
      ">>>best acc: 10.01, mean: 15.74, std: 3.54.........................]  Step: 76ms | Tot: 2s245ms | test_Loss: 4.143 | test_Acc: 14.067% (422/3000) 30/100 \n",
      ">>>best acc: 10.01, mean: 15.68, std: 3.5..........................]  Step: 76ms | Tot: 2s322ms | test_Loss: 4.125 | test_Acc: 14.032% (435/3100) 31/100 \n",
      ">>>best acc: 10.01, mean: 15.63, std: 3.46.........................]  Step: 76ms | Tot: 2s398ms | test_Loss: 4.128 | test_Acc: 13.906% (445/3200) 32/100 \n",
      ">>>best acc: 10.01, mean: 15.56, std: 3.42.........................]  Step: 75ms | Tot: 2s474ms | test_Loss: 4.148 | test_Acc: 13.485% (445/3300) 33/100 \n",
      ">>>best acc: 10.01, mean: 15.49, std: 3.4..........................]  Step: 77ms | Tot: 2s552ms | test_Loss: 4.154 | test_Acc: 13.176% (448/3400) 34/100 \n",
      ">>>best acc: 10.01, mean: 15.43, std: 3.37.........................]  Step: 80ms | Tot: 2s632ms | test_Loss: 4.154 | test_Acc: 13.286% (465/3500) 35/100 \n",
      ">>>best acc: 10.01, mean: 15.38, std: 3.33.........................]  Step: 78ms | Tot: 2s711ms | test_Loss: 4.121 | test_Acc: 13.667% (492/3600) 36/100 \n",
      ">>>best acc: 10.01, mean: 15.33, std: 3.3..........................]  Step: 76ms | Tot: 2s788ms | test_Loss: 4.114 | test_Acc: 13.595% (503/3700) 37/100 \n",
      ">>>best acc: 10.01, mean: 15.28, std: 3.27.........................]  Step: 76ms | Tot: 2s864ms | test_Loss: 4.127 | test_Acc: 13.395% (509/3800) 38/100 \n",
      ">>>best acc: 10.01, mean: 15.22, std: 3.25.........................]  Step: 76ms | Tot: 2s940ms | test_Loss: 4.160 | test_Acc: 13.051% (509/3900) 39/100 \n",
      ">>>best acc: 10.01, mean: 15.19, std: 3.22.........................]  Step: 76ms | Tot: 3s17ms | test_Loss: 4.131 | test_Acc: 13.825% (553/4000) 40/100 \n",
      ">>>best acc: 10.01, mean: 15.16, std: 3.18.........................]  Step: 76ms | Tot: 3s93ms | test_Loss: 4.120 | test_Acc: 14.073% (577/4100) 41/100 \n",
      ">>>best acc: 10.01, mean: 15.14, std: 3.15.........................]  Step: 83ms | Tot: 3s177ms | test_Loss: 4.117 | test_Acc: 14.262% (599/4200) 42/100 \n",
      ">>>best acc: 10.01, mean: 15.12, std: 3.11.........................]  Step: 76ms | Tot: 3s254ms | test_Loss: 4.112 | test_Acc: 14.116% (607/4300) 43/100 \n",
      ">>>best acc: 10.01, mean: 15.1, std: 3.08..........................]  Step: 76ms | Tot: 3s330ms | test_Loss: 4.085 | test_Acc: 14.318% (630/4400) 44/100 \n",
      ">>>best acc: 10.01, mean: 15.08, std: 3.05.........................]  Step: 76ms | Tot: 3s407ms | test_Loss: 4.092 | test_Acc: 14.333% (645/4500) 45/100 \n",
      ">>>best acc: 10.01, mean: 15.07, std: 3.02.........................]  Step: 93ms | Tot: 3s501ms | test_Loss: 4.087 | test_Acc: 14.522% (668/4600) 46/100 \n",
      ">>>best acc: 10.01, mean: 15.05, std: 2.99.........................]  Step: 78ms | Tot: 3s579ms | test_Loss: 4.079 | test_Acc: 14.340% (674/4700) 47/100 \n",
      ">>>best acc: 10.01, mean: 15.03, std: 2.96.........................]  Step: 80ms | Tot: 3s660ms | test_Loss: 4.078 | test_Acc: 14.042% (674/4800) 48/100 \n",
      ">>>best acc: 10.01, mean: 15.01, std: 2.93.........................]  Step: 77ms | Tot: 3s737ms | test_Loss: 4.062 | test_Acc: 14.102% (691/4900) 49/100 \n",
      ">>>best acc: 10.01, mean: 14.99, std: 2.9..........................]  Step: 84ms | Tot: 3s821ms | test_Loss: 4.074 | test_Acc: 14.000% (700/5000) 50/100 \n",
      ">>>best acc: 10.01, mean: 14.97, std: 2.88.........................]  Step: 76ms | Tot: 3s898ms | test_Loss: 4.069 | test_Acc: 14.020% (715/5100) 51/100 \n",
      ">>>best acc: 10.01, mean: 14.96, std: 2.85.........................]  Step: 78ms | Tot: 3s976ms | test_Loss: 4.061 | test_Acc: 14.250% (741/5200) 52/100 \n",
      ">>>best acc: 10.01, mean: 14.94, std: 2.83.........................]  Step: 76ms | Tot: 4s53ms | test_Loss: 4.084 | test_Acc: 14.000% (742/5300) 53/100 \n",
      ">>>best acc: 10.01, mean: 14.93, std: 2.8..........................]  Step: 76ms | Tot: 4s129ms | test_Loss: 4.085 | test_Acc: 14.074% (760/5400) 54/100 \n",
      ">>>best acc: 10.01, mean: 14.91, std: 2.78.........................]  Step: 92ms | Tot: 4s222ms | test_Loss: 4.091 | test_Acc: 14.018% (771/5500) 55/100 \n",
      ">>>best acc: 10.01, mean: 14.89, std: 2.76.........................]  Step: 77ms | Tot: 4s300ms | test_Loss: 4.090 | test_Acc: 13.857% (776/5600) 56/100 \n",
      ">>>best acc: 10.01, mean: 14.87, std: 2.74.........................]  Step: 77ms | Tot: 4s378ms | test_Loss: 4.098 | test_Acc: 13.667% (779/5700) 57/100 \n",
      ">>>best acc: 10.01, mean: 14.86, std: 2.72.........................]  Step: 77ms | Tot: 4s456ms | test_Loss: 4.077 | test_Acc: 14.103% (818/5800) 58/100 \n",
      ">>>best acc: 10.01, mean: 14.84, std: 2.7..........................]  Step: 77ms | Tot: 4s533ms | test_Loss: 4.068 | test_Acc: 14.068% (830/5900) 59/100 \n",
      ">>>best acc: 10.01, mean: 14.83, std: 2.68.........................]  Step: 76ms | Tot: 4s610ms | test_Loss: 4.071 | test_Acc: 13.983% (839/6000) 60/100 \n",
      ">>>best acc: 10.01, mean: 14.81, std: 2.66.........................]  Step: 82ms | Tot: 4s692ms | test_Loss: 4.077 | test_Acc: 13.787% (841/6100) 61/100 \n",
      ">>>best acc: 10.01, mean: 14.79, std: 2.64.........................]  Step: 76ms | Tot: 4s769ms | test_Loss: 4.086 | test_Acc: 13.645% (846/6200) 62/100 \n",
      ">>>best acc: 10.01, mean: 14.78, std: 2.62>........................]  Step: 76ms | Tot: 4s845ms | test_Loss: 4.078 | test_Acc: 13.921% (877/6300) 63/100 \n",
      ">>>best acc: 10.01, mean: 14.77, std: 2.6=>........................]  Step: 76ms | Tot: 4s922ms | test_Loss: 4.069 | test_Acc: 14.047% (899/6400) 64/100 \n",
      ">>>best acc: 10.01, mean: 14.76, std: 2.58=>.......................]  Step: 76ms | Tot: 4s999ms | test_Loss: 4.052 | test_Acc: 14.138% (919/6500) 65/100 \n",
      ">>>best acc: 10.01, mean: 14.75, std: 2.57==>......................]  Step: 77ms | Tot: 5s76ms | test_Loss: 4.064 | test_Acc: 13.970% (922/6600) 66/100 \n",
      ">>>best acc: 10.01, mean: 14.73, std: 2.55==>......................]  Step: 77ms | Tot: 5s154ms | test_Loss: 4.054 | test_Acc: 13.910% (932/6700) 67/100 \n",
      ">>>best acc: 10.01, mean: 14.72, std: 2.53===>.....................]  Step: 84ms | Tot: 5s239ms | test_Loss: 4.053 | test_Acc: 13.853% (942/6800) 68/100 \n",
      ">>>best acc: 10.01, mean: 14.71, std: 2.52====>....................]  Step: 78ms | Tot: 5s317ms | test_Loss: 4.062 | test_Acc: 13.710% (946/6900) 69/100 \n",
      ">>>best acc: 10.01, mean: 14.69, std: 2.5=====>....................]  Step: 76ms | Tot: 5s393ms | test_Loss: 4.074 | test_Acc: 13.543% (948/7000) 70/100 \n",
      ">>>best acc: 10.01, mean: 14.67, std: 2.49=====>...................]  Step: 77ms | Tot: 5s470ms | test_Loss: 4.080 | test_Acc: 13.465% (956/7100) 71/100 \n",
      ">>>best acc: 10.01, mean: 14.66, std: 2.48======>..................]  Step: 96ms | Tot: 5s567ms | test_Loss: 4.076 | test_Acc: 13.514% (973/7200) 72/100 \n",
      ">>>best acc: 10.01, mean: 14.64, std: 2.46======>..................]  Step: 77ms | Tot: 5s644ms | test_Loss: 4.065 | test_Acc: 13.863% (1012/7300) 73/100 \n",
      ">>>best acc: 10.01, mean: 14.63, std: 2.45=======>.................]  Step: 82ms | Tot: 5s727ms | test_Loss: 4.054 | test_Acc: 13.892% (1028/7400) 74/100 \n",
      ">>>best acc: 10.01, mean: 14.62, std: 2.43========>................]  Step: 77ms | Tot: 5s805ms | test_Loss: 4.056 | test_Acc: 13.893% (1042/7500) 75/100 \n",
      ">>>best acc: 10.01, mean: 14.61, std: 2.42========>................]  Step: 87ms | Tot: 5s893ms | test_Loss: 4.055 | test_Acc: 13.855% (1053/7600) 76/100 \n",
      ">>>best acc: 10.01, mean: 14.6, std: 2.4===========>...............]  Step: 77ms | Tot: 5s970ms | test_Loss: 4.046 | test_Acc: 13.779% (1061/7700) 77/100 \n",
      ">>>best acc: 10.01, mean: 14.59, std: 2.39==========>..............]  Step: 76ms | Tot: 6s46ms | test_Loss: 4.041 | test_Acc: 13.808% (1077/7800) 78/100 \n",
      ">>>best acc: 10.01, mean: 14.58, std: 2.38==========>..............]  Step: 76ms | Tot: 6s122ms | test_Loss: 4.045 | test_Acc: 13.684% (1081/7900) 79/100 \n",
      ">>>best acc: 10.01, mean: 14.57, std: 2.36===========>.............]  Step: 78ms | Tot: 6s201ms | test_Loss: 4.056 | test_Acc: 13.588% (1087/8000) 80/100 \n",
      ">>>best acc: 10.01, mean: 14.56, std: 2.35============>............]  Step: 77ms | Tot: 6s279ms | test_Loss: 4.072 | test_Acc: 13.481% (1092/8100) 81/100 \n",
      ">>>best acc: 10.01, mean: 14.54, std: 2.34============>............]  Step: 78ms | Tot: 6s357ms | test_Loss: 4.072 | test_Acc: 13.341% (1094/8200) 82/100 \n",
      ">>>best acc: 10.01, mean: 14.53, std: 2.33=============>...........]  Step: 76ms | Tot: 6s434ms | test_Loss: 4.067 | test_Acc: 13.313% (1105/8300) 83/100 \n",
      ">>>best acc: 10.01, mean: 14.52, std: 2.32=============>...........]  Step: 78ms | Tot: 6s513ms | test_Loss: 4.045 | test_Acc: 13.667% (1148/8400) 84/100 \n",
      ">>>best acc: 10.01, mean: 14.5, std: 2.31===============>..........]  Step: 77ms | Tot: 6s590ms | test_Loss: 4.048 | test_Acc: 13.565% (1153/8500) 85/100 \n",
      ">>>best acc: 10.01, mean: 14.49, std: 2.3================>.........]  Step: 77ms | Tot: 6s667ms | test_Loss: 4.041 | test_Acc: 13.605% (1170/8600) 86/100 \n",
      ">>>best acc: 10.01, mean: 14.48, std: 2.28===============>.........]  Step: 85ms | Tot: 6s752ms | test_Loss: 4.039 | test_Acc: 13.552% (1179/8700) 87/100 \n",
      ">>>best acc: 10.01, mean: 14.47, std: 2.27================>........]  Step: 76ms | Tot: 6s829ms | test_Loss: 4.042 | test_Acc: 13.523% (1190/8800) 88/100 \n",
      ">>>best acc: 10.01, mean: 14.46, std: 2.26=================>.......]  Step: 77ms | Tot: 6s906ms | test_Loss: 4.032 | test_Acc: 13.787% (1227/8900) 89/100 \n",
      ">>>best acc: 10.01, mean: 14.46, std: 2.25=================>.......]  Step: 77ms | Tot: 6s984ms | test_Loss: 4.032 | test_Acc: 13.711% (1234/9000) 90/100 \n",
      ">>>best acc: 10.01, mean: 14.45, std: 2.24==================>......]  Step: 76ms | Tot: 7s60ms | test_Loss: 4.040 | test_Acc: 13.604% (1238/9100) 91/100 \n",
      ">>>best acc: 10.01, mean: 14.44, std: 2.23===================>.....]  Step: 78ms | Tot: 7s139ms | test_Loss: 4.035 | test_Acc: 13.652% (1256/9200) 92/100 \n",
      ">>>best acc: 10.01, mean: 14.43, std: 2.22===================>.....]  Step: 77ms | Tot: 7s216ms | test_Loss: 4.040 | test_Acc: 13.624% (1267/9300) 93/100 \n",
      ">>>best acc: 10.01, mean: 14.42, std: 2.21====================>....]  Step: 78ms | Tot: 7s294ms | test_Loss: 4.030 | test_Acc: 13.851% (1302/9400) 94/100 \n",
      ">>>best acc: 10.01, mean: 14.42, std: 2.2======================>...]  Step: 76ms | Tot: 7s371ms | test_Loss: 4.029 | test_Acc: 13.905% (1321/9500) 95/100 \n",
      ">>>best acc: 10.01, mean: 14.41, std: 2.19=====================>...]  Step: 77ms | Tot: 7s449ms | test_Loss: 4.021 | test_Acc: 14.052% (1349/9600) 96/100 \n",
      ">>>best acc: 10.01, mean: 14.41, std: 2.17======================>..]  Step: 76ms | Tot: 7s526ms | test_Loss: 4.015 | test_Acc: 14.227% (1380/9700) 97/100 \n",
      ">>>best acc: 10.01, mean: 14.41, std: 2.16=======================>.]  Step: 96ms | Tot: 7s622ms | test_Loss: 4.001 | test_Acc: 14.306% (1402/9800) 98/100 \n",
      ">>>best acc: 10.01, mean: 14.41, std: 2.15=======================>.]  Step: 76ms | Tot: 7s699ms | test_Loss: 3.988 | test_Acc: 14.374% (1423/9900) 99/100 \n",
      " [================================================================>]  Step: 84ms | Tot: 7s783ms | test_Loss: 3.988 | test_Acc: 14.530% (1453/10000) 100/100 \n",
      ">>>best acc: 10.01, mean: 14.41, std: 2.14\n",
      "Saving..\n",
      ">>>best acc: 14.53\n",
      "Epoch:3/90\n",
      " [================================================================>]  Step: 130ms | Tot: 2m9s | train_Loss: 3.692 | train_Acc: 18.275% (18056/98800) 988/1000 00 \r"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "wandb.watch(net)\n",
    "\n",
    "\n",
    "epochs = 90\n",
    "def train(epoch):\n",
    "    print('Epoch:{0}/{1}'.format(epoch, epochs))\n",
    "    net.train()\n",
    "    \n",
    "    train_loss = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)        \n",
    "        loss = criterion(outputs, targets)       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'train_Loss: %.3f | train_Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    return train_loss/(batch_idx+1), 100.*correct/total\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    acc_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            acc_list.append(100.*correct/total)\n",
    "            \n",
    "            progress_bar(batch_idx, len(testloader), 'test_Loss: %.3f | test_Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            print('>>>best acc: {0}, mean: {1}, std: {2}'.format(best_acc, round(np.mean(acc_list), 2), round(np.std(acc_list), 2)))\n",
    "            \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(save_path+'/checkpoint'):\n",
    "            os.mkdir(save_path+'/checkpoint')\n",
    "        torch.save(state, save_path+'/checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        print('>>>best acc:', best_acc)\n",
    "    \n",
    "    return test_loss/(batch_idx+1), 100.*correct/total, best_acc\n",
    "\n",
    "test_loss = 0\n",
    "test_list = []\n",
    "train_list = []\n",
    "epoch_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "for epoch in range(start_epoch, start_epoch+epochs):\n",
    "   \n",
    "    epoch_list.append(epoch)\n",
    "    \n",
    "    train_loss, train_acc = train(epoch)\n",
    "    train_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    \n",
    "    test_loss, test_acc, best_acc = test(epoch)\n",
    "    test_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    \n",
    "    epoch_line = 'epoch: {0}/ total epoch: {1} '.format(epoch, epochs) \n",
    "    best_acc_line = 'best_acc: {0} '.format(best_acc)\n",
    "    accuracy_line = 'train_acc: {0} %, test_acc: {1} % '.format(train_acc, test_acc)\n",
    "    loss_line = 'train_loss: {0},e test_loss: {1} '.format(train_loss, test_loss)\n",
    "    wandb.log({\"train accuracy\" : train_acc, \"test accuracy\" : test_acc, \"train_loss\" : train_loss, \"test_loss\" : test_loss}, step=epoch+1)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        plt.figure()\n",
    "        ax1 = plt.subplot(2, 1, 1)\n",
    "        ax1.plot(epoch_list, train_list, c = 'blue', label = 'train loss')\n",
    "        ax1.plot(epoch_list, test_list, c = 'red', label = 'test loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        ax1.legend(loc=0)\n",
    "        \n",
    "        ax2 = plt.subplot(2, 1, 2)\n",
    "        ax2.plot(epoch_list, train_acc_list, c = 'blue', label = 'train acc')\n",
    "        ax2.plot(epoch_list, test_acc_list, c = 'red', label = 'test acc')\n",
    "        plt.ylabel('acc')\n",
    "        plt.xlabel('epoch')\n",
    "        ax2.legend(loc=0)\n",
    "        \n",
    "        plt.savefig(save_path+'/train_history.png')\n",
    "\n",
    "    \n",
    "    with open(save_path+'/logs.txt', 'a') as f:\n",
    "        f.write(epoch_line + best_acc_line + accuracy_line + loss_line + '\\n')\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
